{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master HN PSL â€“ NLP - 29/03/2022\n",
    "\n",
    "## [Spacy](https://spacy.io)\n",
    "\n",
    "Notebook conÃ§u par C. Plancq (2021), mise Ã  jour T. Poibeau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BibliothÃ¨que logicielle de TAL Ã©crite en Python (et Cython)\n",
    "- Ã‰tiquetage POS, lemmatisation, analyse syntaxique, entitÃ©s nommÃ©es, word embedding, transformers\n",
    "- Usage de modÃ¨les neuronaux\n",
    "- IntÃ©gration aisÃ©e de bibliothÃ¨ques de deep learning\n",
    "- v3.0.3 ([github](https://github.com/explosion/spaCy))\n",
    "- Licence MIT (Open Source) pour le code\n",
    "    - Licences ouvertes diverses pour les modÃ¨les\n",
    "- Produit de la sociÃ©tÃ© [explosion.ai](https://explosion.ai/). FondÃ© par :Â Matthew Honnibal ([@honnibal](https://twitter.com/honnibal)) et Ines Montani ([@_inesmontani](https://twitter.com/_inesmontani))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourquoi Spacy ?\n",
    "\n",
    "- C'est du Python ğŸ™Œ ğŸ‰\n",
    "- PlutÃ´t simple Ã  prendre en main\n",
    "- TrÃ¨s bien documentÃ©, Ã  notre avis. D'ailleurs plutÃ´t que ce notebook, suivez l'excellent tutorial d'Ines Montani : [https://course.spacy.io/](https://course.spacy.io/)\n",
    "- Couvre les traitements d'une chaÃ®ne de TAL typique\n",
    "- Pas mal utilisÃ© dans l'industrie\n",
    "- MAIS ce n'est pas forcÃ©ment l'outil qui donne les meilleurs rÃ©sultats pour le franÃ§ais dans toutes les tÃ¢ches de TAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy et les autres\n",
    "\n",
    "Spacy est *un* des frameworks de TAL disponibles\n",
    "\n",
    "- [NLTK](http://www.nltk.org/) :Â python, orientÃ© pÃ©dagogie, pas de modÃ¨les neuronaux inclus mais se combine bien avec TensorFlow, PyTorch ou AlleNLP\n",
    "- [Stanford CoreÂ NLP](https://stanfordnlp.github.io/stanfordnlp/) :Â java, modÃ¨les pour 53 langues (UD), rÃ©solution de la corÃ©ference.\n",
    "- [Stanza](https://stanfordnlp.github.io/stanza/) :Â python, nouveau framework de Stanford, modÃ¨les neuronaux entraÃ®nÃ©s sur donnÃ©es UD <small>[https://github.com/explosion/spacy-stanza](https://github.com/explosion/spacy-stanza) permet d'utiliser les modÃ¨les de Stanford avec Spacy</small>\n",
    "- [TextBlob](https://textblob.readthedocs.io/en/dev/)\n",
    "- [DKPro](https://dkpro.github.io/)\n",
    "- [flair](https://github.com/zalandoresearch/flair) : le framework de Zalando, trÃ¨s bonnes performances en reconnaissance d'entitÃ©s nommÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installation\n",
    "\n",
    "dans un terminal\n",
    "```bash\n",
    "python3 -m pip install -U --user spacy \n",
    "#ou pip install -U --user spacy\n",
    "```\n",
    "- installation du modÃ¨le franÃ§ais\n",
    "```bash\n",
    "python3 -m spacy download fr_core_news_md\n",
    "#ou python3 -m spacy download fr_core_news_sm \n",
    "```\n",
    "- vÃ©rification\n",
    "```bash\n",
    "python3 -m spacy validate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modÃ¨les\n",
    "\n",
    "- Spacy utilise des modÃ¨les statistiques qui permettent de prÃ©dire des annotations linguistiques\n",
    "- 16 langues :Â allemand, anglais, chinois, danois, espagnol, franÃ§ais, italien, japonais, lituanien, nÃ©erlandais, grec, norvÃ©gien, polonais, portugais, roumain, russe + modÃ¨le multi langues\n",
    "- 4 modÃ¨les pour le franÃ§ais\n",
    "    - fr_core_news_sm (tagger, morphologizer, lemmatizer, parser, ner) 16 Mo\n",
    "    - fr_core_news_md (tagger, morphologizer, lemmatizer, parser, ner, vectors) 45 Mo\n",
    "    - fr_core_news_lg (tagger, morphologizer, lemmatizer, parser, ner, vectors) 546 Mo\n",
    "    - fr_dep_news_trf (tagger, morphologizer, lemmatizer, parser) 381 Mo\n",
    "- modÃ¨les `fr` appris sur les corpus [Sequoia](https://deep-sequoia.inria.fr/fr/) et [WikiNer](https://figshare.com/articles/Learning_multilingual_named_entity_recognition_from_Wikipedia/5462500) sauf le modÃ¨le `trf` qui est issu de camembert-base distribuÃ© par [Hugging Face](https://huggingface.co/camembert-base).\n",
    "- Tous ces modÃ¨les, quelque soient leur type ou leur langue, s'utilisent de la mÃªme faÃ§on, avec la mÃªme API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage\n",
    "\n",
    "- *si vous voulez utiliser Spacy prenez le temps de lire la [documentation](https://spacy.io/usage), ici ce ne sera qu'un coup d'Å“il incomplet*\n",
    "- un modÃ¨le est une instance de la classe `Language`, il est adaptÃ© Ã  une langue en particulier\n",
    "- un modÃ¨le incorpore un vocabulaire, des poids, des vecteurs de mots, une configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.fr.French"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- le traitement fonctionne avec un [*pipeline*](https://spacy.io/usage/spacy-101#pipelines) pour convertir un texte en objet `Doc` (texte annotÃ©)\n",
    "- par dÃ©faut `tokenizer` > `tagger` > `parser` > `ner` > `â€¦`\n",
    "- depuis la v3 le pipeline devient `tok2vec` > `morphologizer` > `parser` > `ner` > `attribute_ruler` > `lemmatizer`  \n",
    "  ou `transformer` > `morphologizer` > `parser` > `ner` > `attribute_ruler` > `lemmatizer`\n",
    "- l'utilisateur peut ajouter des Ã©tapes ou en retrancher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x138a0c040>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x29516ee80>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x10fd207c0>),\n",
       " ('lemmatizer', <spacy.lang.fr.lemmatizer.FrenchLemmatizer at 0x1389f2bc0>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md', disable=[\"parser\", \"ner\"])\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retour au pipeline par dÃ©faut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x10fb52220>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x10fb528e0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x10fb9f820>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x138fef300>),\n",
       " ('lemmatizer', <spacy.lang.fr.lemmatizer.FrenchLemmatizer at 0x1388f9e00>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x10fb9fe40>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Un objet `Doc` est une sÃ©quence d'objets `Token` (voir l'[API](https://spacy.io/api/token))\n",
    " - Le texte d'origine est dÃ©coupÃ© en phrases, tokenizÃ©, annotÃ© en POS, lemme, syntaxe (dÃ©pendance) et en entitÃ©s nommÃ©es (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Lâ€™Organisation des Nations unies (ONU) a lancÃ© mardi un appel dâ€™urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ tokenization\n",
    "\n",
    "La tokenization de Spacy est non-destructive. Vous pouvez dÃ©couper un texte en tokens et le restituer dans sa forme originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'\n",
      "Organisation\n",
      "des\n",
      "Nations\n",
      "unies\n",
      "(\n",
      "ONU\n",
      ")\n",
      "a\n",
      "lancÃ©\n",
      "mardi\n",
      "un\n",
      "appel\n",
      "d'\n",
      "urgence\n",
      "pour\n",
      "lever\n",
      "des\n",
      "dizaines\n",
      "de\n",
      "millions\n",
      "de\n",
      "dollars\n",
      "afin\n",
      "de\n",
      "protÃ©ger\n",
      "les\n",
      "rÃ©fugiÃ©s\n",
      "vulnÃ©rables\n",
      "face\n",
      "Ã \n",
      "la\n",
      "propagation\n",
      "du\n",
      "nouveau\n",
      "coronavirus\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"L'Organisation des Nations unies (ONU) a lancÃ© mardi un appel d'urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Organisation des Nations unies (ONU) a lancÃ© mardi un appel d'urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus."
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text_with_ws, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ Ã©tiquetage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les annotations portant sur les tokens sont accessibles via les attributs des objets de type `token`â€¯: [https://spacy.io/api/token#attributes](https://spacy.io/api/token#attributes)  \n",
    "  - `pos_` contient l'Ã©tiquette de partie du discours de [universal dependancies](https://universaldependencies.org/docs/u/pos/)\n",
    "  - `tag_` contient l'Ã©tiquette du corpus original, parfois plus dÃ©taillÃ©e\n",
    "  - `lemma_` pour le lemme\n",
    "  - `morph` pour l'analyse morphologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L' DET Definite=Def|Number=Sing|PronType=Art le\n",
      "Organisation NOUN Gender=Fem|Number=Sing organisation\n",
      "des ADP Definite=Def|Number=Plur|PronType=Art de\n",
      "Nations PROPN  Nations\n",
      "unies ADJ Gender=Fem|Number=Plur uni\n",
      "( PUNCT  (\n",
      "ONU PROPN Gender=Fem|Number=Sing ONU\n",
      ") PUNCT  )\n",
      "a AUX Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin avoir\n",
      "lancÃ© VERB Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part lancer\n",
      "mardi NOUN Gender=Masc|Number=Sing mardi\n",
      "un DET Definite=Ind|Gender=Masc|Number=Sing|PronType=Art un\n",
      "appel NOUN Gender=Masc|Number=Sing appel\n",
      "d' ADP  de\n",
      "urgence NOUN Gender=Fem|Number=Sing urgence\n",
      "pour ADP  pour\n",
      "lever VERB VerbForm=Inf lever\n",
      "des DET Definite=Ind|Number=Plur|PronType=Art un\n",
      "dizaines NOUN Gender=Fem|Number=Plur dizaine\n",
      "de ADP  de\n",
      "millions NOUN Gender=Masc|NumType=Card|Number=Plur million\n",
      "de ADP  de\n",
      "dollars NOUN Gender=Masc|Number=Plur dollar\n",
      "afin ADV  afin\n",
      "de ADP  de\n",
      "protÃ©ger VERB VerbForm=Inf protÃ©ger\n",
      "les DET Definite=Def|Number=Plur|PronType=Art le\n",
      "rÃ©fugiÃ©s NOUN Gender=Masc|Number=Plur rÃ©fugiÃ©\n",
      "vulnÃ©rables ADJ Number=Plur vulnÃ©rable\n",
      "face NOUN Gender=Fem|Number=Sing face\n",
      "Ã  ADP  Ã \n",
      "la DET Definite=Def|Gender=Fem|Number=Sing|PronType=Art le\n",
      "propagation NOUN Gender=Fem|Number=Sing propagation\n",
      "du ADP Definite=Def|Gender=Masc|Number=Sing|PronType=Art de\n",
      "nouveau ADJ Gender=Masc|Number=Sing nouveau\n",
      "coronavirus NOUN Gender=Masc|Number=Sing coronavirus\n",
      ". PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.morph, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour traiter plusieurs textes en sÃ©rie, il est recommandÃ© d'utiliser [nlp.pipe](https://spacy.io/api/language#pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Cadine avait un trÃ¨s-mauvais caractÃ¨re. Elle ne sâ€™accommodait pas du rÃ´le de servante.\",\n",
    "    \"Aussi finit-elle par sâ€™Ã©tablir pour son compte.\",\n",
    "    \"Comme elle Ã©tait alors Ã¢gÃ©e de treize ans, et quâ€™elle ne pouvait rÃªver le grand commerce, un banc de vente de lâ€™allÃ©e aux fleurs, elle vendit des bouquets de violettes dâ€™un sou, piquÃ©s dans un lit de mousse, sur un Ã©ventaire dâ€™osier pendu Ã  son cou.\",\n",
    "    \"Elle rÃ´dait toute la journÃ©e dans les Halles, autour des Halles, promenant son bout de pelouse.\",\n",
    "    \"Câ€™Ã©tait lÃ  sa joie, cette flÃ¢nerie continuelle, qui lui dÃ©gourdissait les jambes, qui la tirait des longues heures passÃ©es Ã  faire des bouquets, les genoux pliÃ©s, sur une chaise basse.\",\n",
    "    \"Maintenant, elle tournait ses violettes en marchant, elle les tournait comme des fuseaux, avec une merveilleuse lÃ©gÃ¨retÃ© de doigts ; elle comptait six Ã  huit fleurs, selon la saison, pliait en deux un brin de jonc, ajoutait une feuille, roulait un fil mouillÃ© ; et, entre ses dents de jeune loup, elle cassait le fil.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€Â vous  \n",
    "1. Extrayez de la sÃ©rie de phrases ci-dessus la liste des noms communs\n",
    "2. Comptez le nombre de tokens au masculin et au fÃ©minin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cou, caractÃ¨re, bout, sou, banc, chaise, lit, jambes, compte, vente, genoux, mousse, feuille, joie, bouquets, saison, allÃ©e, journÃ©e, servante, pelouse, ans, lÃ©gÃ¨retÃ©, brin, fleurs, violettes, osier, loup, doigts, heures, fuseaux, dents, Halles, fil, merveilleuse, rÃ´le, Ã©ventaire, commerce, flÃ¢nerie\n"
     ]
    }
   ],
   "source": [
    "# Extrayez de la sÃ©rie de phrases ci-dessus la liste des noms communs\n",
    "\n",
    "ncs = []\n",
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            ncs.append(tok.text)\n",
    "ncs = set(ncs)        \n",
    "print(\", \".join(ncs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Bonjour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc[0].morph.to_dict()[\"Gender\"]))\n",
    "print(type(doc[0].morph.get(\"Gender\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens au masculin :Â 38, tokens au fÃ©minin : 46\n"
     ]
    }
   ],
   "source": [
    "# Comptez le nombre de tokens au masculin et au fÃ©minin\n",
    "\n",
    "nb_masc = 0\n",
    "nb_fem = 0\n",
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    for tok in doc:\n",
    "        if tok.morph.get(\"Gender\") == [\"Masc\"]:\n",
    "            nb_masc += 1\n",
    "        elif tok.morph.get(\"Gender\") == [\"Fem\"]:\n",
    "            nb_fem += 1\n",
    "        \n",
    "print(f\"tokens au masculin :Â {nb_masc}, tokens au fÃ©minin : {nb_fem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ analyse syntaxique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse syntaxique ou *parsing* de Spacy est une analyse en dÃ©pendance. La plupart sinon la totalitÃ© des modÃ¨les utilisÃ©s viennent de https://universaldependencies.org\n",
    "\n",
    "Dans l'analyse en dÃ©pendance produite par Spacy, chaque mot d'une phrase a un gouverneur unique (*head*), la relation de dÃ©pendance entre le mot et son gouverneur est typÃ©e (*nsubj*, *obj*, â€¦).  \n",
    "Pour la tÃªte de la phrase on utilise la relation *ROOT*.\n",
    "\n",
    "La structure produite par l'analyse syntaxique est un arbre, un graphe acyclique et connexe. Les tokens sont les nÅ“uds, les arcs sont les dÃ©pendances, le type de la relation est l'Ã©tiquette de l'arc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`displacy` fournit un outil de visualisation bien pratique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"3a6c6b65f19647eb8501a203b5ee67d9-0\" class=\"displacy\" width=\"1220\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">DerriÃ¨re</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">lui,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">le</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">carreau</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">rue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">Rambuteau,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">vendait</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">des</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">fruits.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-0\" stroke-width=\"2px\" d=\"M70,227.0 C70,182.0 120.0,182.0 120.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,229.0 L62,217.0 78,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-1\" stroke-width=\"2px\" d=\"M160,227.0 C160,2.0 950.0,2.0 950.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,229.0 L152,217.0 168,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-2\" stroke-width=\"2px\" d=\"M250,227.0 C250,137.0 395.0,137.0 395.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,229.0 L242,217.0 258,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-3\" stroke-width=\"2px\" d=\"M340,227.0 C340,182.0 390.0,182.0 390.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,229.0 L332,217.0 348,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-4\" stroke-width=\"2px\" d=\"M430,227.0 C430,47.0 945.0,47.0 945.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,229.0 L422,217.0 438,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-5\" stroke-width=\"2px\" d=\"M520,227.0 C520,137.0 665.0,137.0 665.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,229.0 L512,217.0 528,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-6\" stroke-width=\"2px\" d=\"M610,227.0 C610,182.0 660.0,182.0 660.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,229.0 L602,217.0 618,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-7\" stroke-width=\"2px\" d=\"M430,227.0 C430,92.0 670.0,92.0 670.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670.0,229.0 L678.0,217.0 662.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-8\" stroke-width=\"2px\" d=\"M700,227.0 C700,182.0 750.0,182.0 750.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,229.0 L758.0,217.0 742.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-9\" stroke-width=\"2px\" d=\"M880,227.0 C880,182.0 930.0,182.0 930.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,229.0 L872,217.0 888,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-10\" stroke-width=\"2px\" d=\"M1060,227.0 C1060,182.0 1110.0,182.0 1110.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,229.0 L1052,217.0 1068,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-11\" stroke-width=\"2px\" d=\"M970,227.0 C970,137.0 1115.0,137.0 1115.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3a6c6b65f19647eb8501a203b5ee67d9-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,229.0 L1123.0,217.0 1107.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={'distance':90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe Ã©galement un outil issu d'un dÃ©veloppement indÃ©pendant :Â [explacy](https://spacy.io/universe/project/explacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep tree     Token     Dep type Lemma     Part of Sp\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "         â”Œâ”€â–º DerriÃ¨re  case     derriÃ¨re  ADP       \n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â–ºâ””â”€â”€ lui       obl:mod  lui       PRON      \n",
      "â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ,         punct    ,         PUNCT     \n",
      "â”‚â”‚      â”Œâ”€â”€â–º sur       case     sur       ADP       \n",
      "â”‚â”‚      â”‚â”Œâ”€â–º le        det      le        DET       \n",
      "â”‚â”‚â”Œâ”€â–ºâ”Œâ”€â”€â”´â”´â”€â”€ carreau   obl:mod  carreau   NOUN      \n",
      "â”‚â”‚â”‚  â”‚  â”Œâ”€â”€â–º de        case     de        ADP       \n",
      "â”‚â”‚â”‚  â”‚  â”‚â”Œâ”€â–º la        det      le        DET       \n",
      "â”‚â”‚â”‚  â””â”€â–ºâ””â”¼â”€â”€ rue       nmod     rue       NOUN      \n",
      "â”‚â”‚â”‚      â””â”€â–º Rambuteau nmod     Rambuteau PROPN     \n",
      "â”‚â”‚â”‚     â”Œâ”€â”€â–º ,         punct    ,         PUNCT     \n",
      "â”‚â”‚â”‚     â”‚â”Œâ”€â–º on        nsubj    on        PRON      \n",
      "â””â”´â”´â”€â”€â”¬â”¬â”€â”´â”´â”€â”€ vendait   ROOT     vendre    VERB      \n",
      "     â”‚â”‚  â”Œâ”€â–º des       det      un        DET       \n",
      "     â”‚â””â”€â–ºâ””â”€â”€ fruits    obj      fruit     NOUN      \n",
      "     â””â”€â”€â”€â”€â”€â–º .         punct    .         PUNCT     \n"
     ]
    }
   ],
   "source": [
    "import explacy\n",
    "explacy.print_parse_info(nlp, 'DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi rÃ©cupÃ©rer parcourir les tokens et afficher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerriÃ¨re CASE lui\n",
      "lui OBL:MOD vendait\n",
      ", PUNCT vendait\n",
      "sur CASE carreau\n",
      "le DET carreau\n",
      "carreau OBL:MOD vendait\n",
      "de CASE rue\n",
      "la DET rue\n",
      "rue NMOD carreau\n",
      "Rambuteau NMOD rue\n",
      ", PUNCT vendait\n",
      "on NSUBJ vendait\n",
      "vendait ROOT vendait\n",
      "des DET fruits\n",
      "fruits OBJ vendait\n",
      ". PUNCT vendait\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.dep_.upper(), token.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs de token suivant peuvent Ãªtre utilisÃ©s pour parcourir l'arbre de dÃ©pendance :Â \n",
    "- `children` les tokens dÃ©pendants du token\n",
    "- `subtree` tous les descendants du token\n",
    "- `ancestors` tous les parents du token\n",
    "- `rights` les enfants Ã  droite du token\n",
    "- `lefts` les enfants Ã  gauche du token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut extraire de la phrase prÃ©cÃ©dente le triplet sujet-verbe-objet comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(on, vendait, fruits)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = [token for token in doc if token.head == token][0]\n",
    "subjects = [tok for tok in root.lefts if tok.dep_ == \"nsubj\"]\n",
    "subject = subjects[0]\n",
    "objs = [tok for tok in root.rights if tok.dep_ == \"obj\"]\n",
    "obj = objs[0]\n",
    "subject, root, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des\n",
      "fruits\n"
     ]
    }
   ],
   "source": [
    "for obj in objs:\n",
    "    for descendant in obj.subtree:\n",
    "        print(descendant.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€Â vous\n",
    "\n",
    "1. Trouver et afficher l'objet de la phrase :Â Â« Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle. Â»\n",
    "\n",
    "2. Dans la liste `texts` vue plus haut, retrouvez les verbes dont Cadine ou le pronom 'elle' est sujet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep tree                  Token      Dep type   Lemma      Part of Sp\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                   â”Œâ”€â”€â”€â”€â–º Depuis     mark       depuis     ADP       \n",
      "                   â”‚â”Œâ”€â”€â”€â–º que        mark       que        SCONJ     \n",
      "                   â”‚â”‚â”Œâ”€â”€â–º Google     nsubj      Google     PROPN     \n",
      "                   â”‚â”‚â”‚â”Œâ”€â–º a          aux:tense  avoir      AUX       \n",
      "â”Œâ”€â–ºâ”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”´â”´â”´â”€â”€ annoncÃ©    advcl      annoncer   VERB      \n",
      "â”‚  â”‚     â”‚            â”Œâ”€â–º son        det        son        DET       \n",
      "â”‚  â”‚     â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ intention  obj        intention  NOUN      \n",
      "â”‚  â”‚        â”‚         â”Œâ”€â–º de         mark       de         ADP       \n",
      "â”‚  â”‚        â””â”€â–ºâ”Œâ”¬â”€â”€â”€â”€â”€â”´â”€â”€ stopper    acl        stopper    VERB      \n",
      "â”‚  â”‚           â”‚â”‚  â”Œâ”€â–ºâ”Œâ”€â”€ d'         case       de         ADP       \n",
      "â”‚  â”‚           â”‚â”‚  â”‚  â””â”€â–º ici        fixed      ici        ADV       \n",
      "â”‚  â”‚           â”‚â”‚  â”‚  â”Œâ”€â–º deux       nummod     deux       NUM       \n",
      "â”‚  â”‚           â”‚â””â”€â–ºâ””â”€â”€â”´â”€â”€ ans        obl:mod    an         NOUN      \n",
      "â”‚  â”‚           â”‚      â”Œâ”€â–º les        det        le         DET       \n",
      "â”‚  â”‚           â””â”€â”€â–ºâ”Œâ”€â”€â”¼â”€â”€ cookies    obj        cookie     NOUN      \n",
      "â”‚  â”‚               â”‚  â””â”€â–º tiers      amod       tiers      ADJ       \n",
      "â”‚  â”‚               â”‚  â”Œâ”€â–º sur        case       sur        ADP       \n",
      "â”‚  â”‚               â””â”€â–ºâ””â”€â”€ Chrome     nmod       Chrome     PROPN     \n",
      "â”‚  â”‚                 â”Œâ”€â”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚  â”‚                 â”‚â”Œâ”€â–º son        det        son        DET       \n",
      "â”‚  â””â”€â–ºâ”Œâ”¬â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”´â”´â”€â”€ moteur     obl:mod    moteur     NOUN      \n",
      "â”‚     â”‚â”‚â”‚          â”‚  â”Œâ”€â–º de         case       de         ADP       \n",
      "â”‚     â”‚â”‚â”‚          â””â”€â–ºâ””â”€â”€ recherche  nmod       recherche  NOUN      \n",
      "â”‚     â”‚â”‚â”‚            â”Œâ”€â”€â–º qui        nsubj:pass qui        PRON      \n",
      "â”‚     â”‚â”‚â”‚            â”‚â”Œâ”€â–º est        aux:pass   Ãªtre       AUX       \n",
      "â”‚     â”‚â”‚â””â”€â–ºâ”Œâ”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”´â”€â”€ utilisÃ©    acl:relcl  utiliser   VERB      \n",
      "â”‚     â”‚â”‚   â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–º par        case       par        ADP       \n",
      "â”‚     â”‚â”‚   â”‚â”‚  â”‚   â”Œâ”€â–ºâ”Œâ”€â”€ plus       advmod     plus       ADV       \n",
      "â”‚     â”‚â”‚   â”‚â”‚  â”‚   â”‚  â””â”€â–º de         fixed      de         ADP       \n",
      "â”‚     â”‚â”‚   â”‚â”‚  â”‚â”Œâ”€â–ºâ””â”€â”€â”€â”€â”€ 60         nummod     60         NUM       \n",
      "â”‚     â”‚â”‚   â”‚â””â”€â–ºâ””â”´â”€â”¬â”€â”€â”€â”€â”€â”€ %          obl:mod    pourcent   NOUN      \n",
      "â”‚     â”‚â”‚   â”‚      â”‚  â”Œâ”€â”€â–º de         case       de         ADP       \n",
      "â”‚     â”‚â”‚   â”‚      â”‚  â”‚â”Œâ”€â–º la         det        le         DET       \n",
      "â”‚     â”‚â”‚   â”‚      â””â”€â–ºâ”œâ”¼â”€â”€ population nmod       population NOUN      \n",
      "â”‚     â”‚â”‚   â”‚         â”‚â””â”€â–º mondiale   amod       mondial    ADJ       \n",
      "â”‚     â”‚â”‚   â”‚         â””â”€â”€â–º connectÃ©e  amod       connecter  VERB      \n",
      "â”‚     â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚     â”‚â”‚              â”Œâ”€â–º les        det        le         DET       \n",
      "â”‚     â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”´â”€â”€ Criteo     appos      criteo     NOUN      \n",
      "â”‚     â”‚            â”‚  â”Œâ”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚     â”‚            â””â”€â–ºâ””â”€â”€ LiveRamp   conj       LiveRamp   PROPN     \n",
      "â”‚     â”‚               â”Œâ”€â–º et         cc         et         CCONJ     \n",
      "â”‚     â”‚            â”Œâ”€â–ºâ””â”€â”€ autres     amod       autre      ADJ       \n",
      "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ””â”€â”€â”¬â”€â”€ Index      nmod       Index      X         \n",
      "â”‚                     â””â”€â–º Exchange   flat:name  Exchange   X         \n",
      "â”‚                     â”Œâ”€â–º se         expl:comp  se         PRON      \n",
      "â””â”€â”€â”€â”€â”€â”¬â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ prÃ©parent  ROOT       prÃ©parer   VERB      \n",
      "      â”‚â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€ Ã           advmod     Ã           ADP       \n",
      "      â”‚   â”‚           â””â”€â–º ce         fixed      ce         PRON      \n",
      "      â”‚   â”‚           â”Œâ”€â–º qui        nsubj      qui        PRON      \n",
      "      â”‚   â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ peut       acl:relcl  pouvoir    VERB      \n",
      "      â”‚      â”‚        â”Œâ”€â–º Ãªtre       aux:pass   Ãªtre       AUX       \n",
      "      â”‚      â””â”€â–ºâ”Œâ”¬â”¬â”€â”€â”€â”´â”€â”€ considÃ©rÃ©  xcomp      considÃ©rer VERB      \n",
      "      â”‚         â”‚â”‚â”‚  â”Œâ”€â”€â–º comme      case       comme      ADP       \n",
      "      â”‚         â”‚â”‚â”‚  â”‚â”Œâ”€â–º un         det        un         DET       \n",
      "      â”‚         â”‚â”‚â””â”€â–ºâ””â”´â”€â”€ sÃ©isme     obl:mod    sÃ©isme     NOUN      \n",
      "      â”‚         â”‚â””â”€â”€â”€â”€â”€â”€â–º ,          punct      ,          PUNCT     \n",
      "      â”‚         â”‚    â”Œâ”€â”€â–º Ã           case       Ã           ADP       \n",
      "      â”‚         â”‚    â”‚â”Œâ”€â–º leur       det        leur       DET       \n",
      "      â”‚         â””â”€â”€â”€â–ºâ””â”´â”€â”€ Ã©chelle    obl:mod    Ã©chelle    NOUN      \n",
      "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º .          punct      .          PUNCT     \n"
     ]
    }
   ],
   "source": [
    "import explacy\n",
    "explacy.print_parse_info(nlp, \"Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "root = [token for token in doc if token.head == token][0]\n",
    "objs = [tok for tok in root.rights if tok.dep_ ==\"obj\"]\n",
    "for obj in objs:\n",
    "    for descendant in obj.subtree:\n",
    "        print(descendant.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matching par rÃ¨gle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy a une classe `Matcher` qui permet de repÃ©rer des tokens ou des suites de tokens Ã  l'aide de patrons (*pattern*). Ces patrons peuvent porter sur la forme des tokens ou leurs attributs (pos, ent).  \n",
    "On peut aussi utiliser des catÃ©gories comme `IS_ALPHA` ou `IS_NUM`, voir la [doc](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8 en taille M\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "# en taille + lettres en maj\n",
    "matcher.add(\"tailles\", [pattern])\n",
    "\n",
    "doc = nlp(\"Ce modÃ¨le est aussi disponible en taille M ; je vous le conseille.\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã‡a fonctionne pour les sÃ©quences comme Â« en taille M Â» ou Â« en taille XL Â» mais pas pour Â« vous l'avez en XL ? Â»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut essayer d'amÃ©liorer les rÃ¨gles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en XL\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# rÃ¨gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou encore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9364735015326875510 tailles 3 5 en XL\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "sizes = ['XS', 'S', 'M', 'L', 'XL']\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# rÃ¨gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€ vous\n",
    "\n",
    "Dans `data/Le_Ventre_de_Paris-short.txt`, trouver les sÃ©quences pronom - le lemme 'vendre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PRON\"}, {\"LEMMA\": \"vendre\"}]\n",
    "matcher.add(\"pro_vendre\", [pattern])\n",
    "\n",
    "doc = \"\"\n",
    "with open('data/Le_Ventre_de_Paris-short.txt') as input_data:\n",
    "    doc = nlp(input_data.read())\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dependancy Matcher :Â extraction de patrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis la v3, Spacy a ajoutÃ© un *Dependancy Matcher* qui permet de faire de l'extraction de patrons syntaxiques. Il est maintenant possible de faire porter des requÃªtes sur l'arbre syntaxique et non plus seulement sur la sÃ©quence des tokens.  \n",
    "Ce dispositif utilise [Semgrex](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html), la syntaxe utilisÃ©e dans Tgrep et Tregex, les outils de requÃªte sur Treebank de Stanford.\n",
    "\n",
    "Voir la [documentation](https://spacy.io/usage/rule-based-matching#dependencymatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventre_short = \"\"\n",
    "with open('data/Le_Ventre_de_Paris-short.txt') as input_f:\n",
    "    ventre_short = input_f.read()\n",
    "doc = nlp(ventre_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "  {\n",
    "    \"RIGHT_ID\": \"vendre\",    \n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": \"vendre\"}\n",
    "  }\n",
    "]\n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for m_id, t_ids in matches:\n",
    "    for t_id in t_ids:\n",
    "        print(doc[t_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"vendre\",    \n",
    "        \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"vendre\", \"acheter\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"sujet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},  \n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"objet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"obj\", \"iobj\", \"obl\"]}},  \n",
    "    }\n",
    "]\n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for m_id, t_ids in matches:\n",
    "    print(\"verbe, sujet, objet :Â \", \" -> \".join([doc[t_id].text for t_id in t_ids]))\n",
    "    print(\"objet complet :Â \", \" \".join([t.text for t in doc[t_ids[2]].subtree]))\n",
    "    print(\"Phrase complÃ©te :Â \", doc[t_ids[0]].sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€ vous\n",
    "\n",
    "Ajouter une rÃ¨gle au motif pour trouver aussi l'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter les traitements de Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. re-tokenisation\n",
    "\n",
    "- voir [https://spacy.io/usage/linguistic-features#retokenization](https://spacy.io/usage/linguistic-features#retokenization)\n",
    "\n",
    "Dans l'exemple qui suit Â« quer-cra Â» sera tokenizÃ© Ã  tort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Pour les bons bails Ã§a va grave quer-cra\")\n",
    "print([(tok.text, tok.pos_, tok.lemma_)for tok in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[7:], attrs={\"LEMMA\": \"quer-cra\", \"POS\": \"NOUN\"})\n",
    "print([(tok.text, tok.pos_) for tok in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention ici câ€™est lâ€™objet doc qui est modifiÃ©, le rÃ©sultat mais pas le traitement. Nous allons voir comment faire pour modifier le traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modification de la tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH, LEMMA, POS, TAG\n",
    "\n",
    "special_case = [{ORTH: \"quer-cra\"}]\n",
    "nlp.tokenizer.add_special_case(\"quer-cra\", special_case)\n",
    "doc = nlp(\"Pour les bons bails Ã§a va grave quer-cra\")\n",
    "print([(tok.text, tok.pos_, tok.lemma_) for tok in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a bien modifiÃ© la tokenisation dans le modÃ¨le `nlp`. Cela n'affecte pas par contre l'Ã©tiquetage en POS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EntitÃ©s nommÃ©es :Â traitement par rÃ¨gles\n",
    " - Voir [https://spacy.io/usage/rule-based-matching#entityruler](https://spacy.io/usage/rule-based-matching#entityruler)\n",
    " \n",
    "Spacy offre aussi un mÃ©canisme de traitement par rÃ¨gle pour les entitÃ©s nommÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "doc = nlp(\"Depuis que machin a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "print(\"Avant : \", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", config={'overwrite_ents':True})\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Chrome\"},\n",
    "            {\"label\":\"ORG\", \"pattern\":\"machin\"},\n",
    "    {\"label\":\"ORG\", \"pattern\":\"Criteo\"},\n",
    "    {\"label\":\"ORG\",\"pattern\":\"LiveRamp\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"Depuis que machin a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "print(\"AprÃ¨s : \", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
